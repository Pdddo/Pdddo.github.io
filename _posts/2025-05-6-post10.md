---
title: Depth-First Search (DFS)
date: 2025-05-27
categories: [desain dan analisis algoritma]
tags: [belajar]     # TAG names should always be lowercase
description: What is Depth-First Search (DFS)?
---


### What Is Breadth-First Search?
Breadth-First Search (BFS) is a fundamental graph traversal algorithm used to explore all the nodes of a graph or 
tree. The core idea is to search "wide" before searching "deep." Starting from a selected source node, BFS 
explores all of its immediate neighbors first. Only after visiting every node at the current "level" or distance 
from the source does it move on to explore the nodes at the next level. This level-by-level exploration strategy 
makes BFS particularly useful for a specific class of problems, most notably finding the shortest path in 
unweighted graphs.

### The Role of the Queue
The magic behind BFS's level-by-level traversal is its use of a **queue** data structure. A queue follows a 
First-In, First-Out (FIFO) principle, meaning the first element added is the first one to be removed. The process 
begins by adding the starting source node to the queue. The algorithm then enters a loop that continues as long as 
the queue is not empty. In each iteration, it dequeues (removes) a node, visits it, and then enqueues (adds) all 
of its unvisited neighbors to the back of the queue. This ensures that nodes are processed in the exact order of 
their distance from the source.

### BFS vs. Depth-First Search (DFS)
It's helpful to contrast BFS with its counterpart, **Depth-First Search (DFS)**. While BFS explores layer by layer 
using a queue, DFS explores as far as possible down one path before backtracking. DFS uses a stack (Last-In, 
First-Out), which gives it a "deep-diving" behavior. The choice between BFS and DFS depends entirely on the 
problem. If you need to find the shortest path between two nodes in an unweighted graph, BFS is the answer. If you 
need to check for cycles, find a path, or explore a maze-like structure, DFS is often a more natural fit.

### A Step-by-Step Example
Let's walk through a simple example. Imagine a graph with nodes A, B, C, and D. A is connected to B and C. B is 
connected to D. Our goal is to start at A.
1.  **Start**: Add the source node **A** to the queue. Queue: [A].
2.  **Dequeue A**: Visit A. Add its unvisited neighbors (B and C) to the queue. Queue: [B, C].
3.  **Dequeue B**: Visit B. Add its unvisited neighbor (D) to the queue. Queue: [C, D].
4.  **Dequeue C**: Visit C. It has no new, unvisited neighbors. Queue: [D].
5.  **Dequeue D**: Visit D. It has no new, unvisited neighbors. Queue: [].
The queue is now empty, and the algorithm terminates. The traversal order was A, B, C, D.

### Finding the Shortest Path
One of the most powerful applications of BFS is finding the **shortest path** between two nodes in an unweighted 
graph. Because BFS explores nodes level by level, the first time it reaches the destination node, it is guaranteed 
to have found a path with the minimum number of edges. This is because it had to explore all paths of length 1, 
then all paths of length 2, and so on. It would be impossible for it to find a longer path to a node before 
finding the shortest one.

### Time and Space Complexity
The efficiency of BFS is straightforward to analyze. Every node and every edge in the graph will be processed 
exactly once. Therefore, its **time complexity** is O(V + E), where 'V' is the number of vertices (nodes) and 'E' 
is the number of edges. The **space complexity** is determined by the maximum number of nodes stored in the queue 
at any given time. In the worst-case scenario (a dense, star-like graph), this could be all the vertices, leading 
to a space complexity of O(V).

### Real-World Applications üåê
Beyond finding the shortest path in video games or GPS navigation, BFS has many other practical uses. Social 
networks like LinkedIn and Facebook use it to find "mutual friends" or suggest connections within a certain degree 
of separation. In computer networking, it's used in protocols like OSPF to broadcast packets. Web crawlers use it 
to index web pages, starting from a source page and exploring all the links at the current level before moving 
deeper. Its simple, level-by-level approach makes it a reliable and efficient tool for a wide range of problems.